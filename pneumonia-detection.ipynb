{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport cv2\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nimport glob\nfrom pathlib import Path\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_inputs(filepath):\n    X = []\n    for file in filepath:\n        img = mpimg.imread(file)\n        resized_img = cv2.resize(img, (64, 64))\n        if len(resized_img.shape)!=3: #Some images have 3 identical channels instead of 1\n            resized_img = np.stack((resized_img, resized_img, resized_img), axis=-1)\n\n        X.append(resized_img)\n    X = np.array(X)\n    y=[]\n    for file in filepath:\n        if \"NORMAL\" in file:\n            y.append(0)\n        if \"PNEUMONIA\" in file:\n            y.append(1)\n    y = np.expand_dims(y, axis=-1)\n    \n    return X, y\ndef type_pred(list_true, list_pred):\n    TP, FP, TN, FN = 0, 0, 0, 0\n    for y_true, y_pred in zip(list_true, list_pred):\n        if not y_true and not y_pred:\n            TN+=1\n        elif not y_true:\n            FP+=1\n        elif not y_pred:\n            FN+=1\n        else:\n            TP+=1\n    return TP, FP, TN, FN\n\ndef get_scores(list_true, list_pred):\n    TP, FP, TN, FN = type_pred(list_true, list_pred)\n    precision = TP/(TP+FP)\n    recall = TP/(TP+FN)\n    F1_score = 2*(precision*recall)/(precision+recall)\n    return precision, recall, F1_score\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = glob.glob('/kaggle/input/chest-xray-pneumonia/chest_xray/train/*/*')+glob.glob('/kaggle/input/chest-xray-pneumonia/chest_xray/val/*/*')+glob.glob('/kaggle/input/chest-xray-pneumonia/chest_xray/test/*/*')\nX, y = get_inputs(filepath)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2, random_state=0)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (X_train.shape, X_valid.shape, X_test.shape)\nprint (y_train.shape, y_valid.shape, y_test.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(4684, 64, 64, 3) (586, 64, 64, 3) (586, 64, 64, 3)\n(4684, 1) (586, 1) (586, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Dense, Flatten, GlobalAveragePooling2D, Dropout\n\nmodel = Sequential()\nconv_base = EfficientNetB0(input_shape=(64, 64, 3), include_top=False, weights='imagenet')\n\nmodel.add(conv_base)\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(BatchNormalization())\n\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nfor layer in conv_base.layers:\n    layer.trainable = False\n    \nmodel.summary()","execution_count":9,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n16711680/16705208 [==============================] - 0s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnetb0 (Functional)  (None, 2, 2, 1280)        4049571   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1280)              0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1280)              5120      \n_________________________________________________________________\ndropout (Dropout)            (None, 1280)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 1281      \n=================================================================\nTotal params: 4,055,972\nTrainable params: 3,841\nNon-trainable params: 4,052,131\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\n\nPath(\"save_models\").mkdir(parents=True, exist_ok=True)\n\nfilepath = \"save_models/effnet.h5\"\n\ncallbacks = [ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1),\n           EarlyStopping(monitor='val_accuracy', patience=10, verbose=1),\n           ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, verbose=1)]\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(lr=1e-2),\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_valid, y_valid), callbacks=callbacks)","execution_count":10,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n147/147 [==============================] - 27s 145ms/step - loss: 0.3844 - accuracy: 0.8620 - val_loss: 0.4312 - val_accuracy: 0.7747\n\nEpoch 00001: val_accuracy improved from -inf to 0.77474, saving model to save_models/effnet.h5\nEpoch 2/50\n147/147 [==============================] - 19s 132ms/step - loss: 0.2686 - accuracy: 0.9133 - val_loss: 0.3308 - val_accuracy: 0.8532\n\nEpoch 00002: val_accuracy improved from 0.77474 to 0.85324, saving model to save_models/effnet.h5\nEpoch 3/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.2540 - accuracy: 0.9227 - val_loss: 0.2086 - val_accuracy: 0.9232\n\nEpoch 00003: val_accuracy improved from 0.85324 to 0.92321, saving model to save_models/effnet.h5\nEpoch 4/50\n147/147 [==============================] - 19s 127ms/step - loss: 0.2553 - accuracy: 0.9202 - val_loss: 0.2069 - val_accuracy: 0.9317\n\nEpoch 00004: val_accuracy improved from 0.92321 to 0.93174, saving model to save_models/effnet.h5\nEpoch 5/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.2718 - accuracy: 0.9096 - val_loss: 0.2753 - val_accuracy: 0.9147\n\nEpoch 00005: val_accuracy did not improve from 0.93174\nEpoch 6/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.2522 - accuracy: 0.9197 - val_loss: 0.2255 - val_accuracy: 0.9386\n\nEpoch 00006: val_accuracy improved from 0.93174 to 0.93857, saving model to save_models/effnet.h5\nEpoch 7/50\n147/147 [==============================] - 19s 130ms/step - loss: 0.2059 - accuracy: 0.9312 - val_loss: 0.2444 - val_accuracy: 0.9215\n\nEpoch 00007: val_accuracy did not improve from 0.93857\nEpoch 8/50\n147/147 [==============================] - 19s 126ms/step - loss: 0.2385 - accuracy: 0.9235 - val_loss: 0.2632 - val_accuracy: 0.9147\n\nEpoch 00008: val_accuracy did not improve from 0.93857\nEpoch 9/50\n147/147 [==============================] - 19s 130ms/step - loss: 0.2245 - accuracy: 0.9252 - val_loss: 0.2559 - val_accuracy: 0.9164\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n\nEpoch 00009: val_accuracy did not improve from 0.93857\nEpoch 10/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.2247 - accuracy: 0.9208 - val_loss: 0.1804 - val_accuracy: 0.9352\n\nEpoch 00010: val_accuracy did not improve from 0.93857\nEpoch 11/50\n147/147 [==============================] - 19s 126ms/step - loss: 0.1778 - accuracy: 0.9372 - val_loss: 0.1748 - val_accuracy: 0.9386\n\nEpoch 00011: val_accuracy did not improve from 0.93857\nEpoch 12/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.1893 - accuracy: 0.9274 - val_loss: 0.1870 - val_accuracy: 0.9249\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n\nEpoch 00012: val_accuracy did not improve from 0.93857\nEpoch 13/50\n147/147 [==============================] - 19s 130ms/step - loss: 0.1582 - accuracy: 0.9420 - val_loss: 0.1610 - val_accuracy: 0.9334\n\nEpoch 00013: val_accuracy did not improve from 0.93857\nEpoch 14/50\n147/147 [==============================] - 19s 128ms/step - loss: 0.1454 - accuracy: 0.9453 - val_loss: 0.1536 - val_accuracy: 0.9454\n\nEpoch 00014: val_accuracy improved from 0.93857 to 0.94539, saving model to save_models/effnet.h5\nEpoch 15/50\n147/147 [==============================] - 19s 128ms/step - loss: 0.1490 - accuracy: 0.9407 - val_loss: 0.1632 - val_accuracy: 0.9403\n\nEpoch 00015: val_accuracy did not improve from 0.94539\nEpoch 16/50\n147/147 [==============================] - 19s 127ms/step - loss: 0.1564 - accuracy: 0.9354 - val_loss: 0.1568 - val_accuracy: 0.9420\n\nEpoch 00016: val_accuracy did not improve from 0.94539\nEpoch 17/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.1442 - accuracy: 0.9420 - val_loss: 0.1440 - val_accuracy: 0.9505\n\nEpoch 00017: val_accuracy improved from 0.94539 to 0.95051, saving model to save_models/effnet.h5\nEpoch 18/50\n147/147 [==============================] - 19s 126ms/step - loss: 0.1532 - accuracy: 0.9421 - val_loss: 0.1523 - val_accuracy: 0.9420\n\nEpoch 00018: val_accuracy did not improve from 0.95051\nEpoch 19/50\n147/147 [==============================] - 19s 127ms/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 0.1504 - val_accuracy: 0.9471\n\nEpoch 00019: val_accuracy did not improve from 0.95051\nEpoch 20/50\n147/147 [==============================] - 18s 126ms/step - loss: 0.1411 - accuracy: 0.9437 - val_loss: 0.1575 - val_accuracy: 0.9437\n\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n\nEpoch 00020: val_accuracy did not improve from 0.95051\nEpoch 21/50\n147/147 [==============================] - 19s 128ms/step - loss: 0.1455 - accuracy: 0.9462 - val_loss: 0.1446 - val_accuracy: 0.9454\n\nEpoch 00021: val_accuracy did not improve from 0.95051\nEpoch 22/50\n147/147 [==============================] - 19s 128ms/step - loss: 0.1492 - accuracy: 0.9432 - val_loss: 0.1494 - val_accuracy: 0.9420\n\nEpoch 00022: val_accuracy did not improve from 0.95051\nEpoch 23/50\n147/147 [==============================] - 19s 126ms/step - loss: 0.1289 - accuracy: 0.9495 - val_loss: 0.1490 - val_accuracy: 0.9471\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n\nEpoch 00023: val_accuracy did not improve from 0.95051\nEpoch 24/50\n147/147 [==============================] - 19s 127ms/step - loss: 0.1522 - accuracy: 0.9412 - val_loss: 0.1495 - val_accuracy: 0.9454\n\nEpoch 00024: val_accuracy did not improve from 0.95051\nEpoch 25/50\n147/147 [==============================] - 19s 127ms/step - loss: 0.1363 - accuracy: 0.9440 - val_loss: 0.1474 - val_accuracy: 0.9454\n\nEpoch 00025: val_accuracy did not improve from 0.95051\nEpoch 26/50\n147/147 [==============================] - 19s 129ms/step - loss: 0.1420 - accuracy: 0.9423 - val_loss: 0.1473 - val_accuracy: 0.9505\n\nEpoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n\nEpoch 00026: val_accuracy did not improve from 0.95051\nEpoch 27/50\n147/147 [==============================] - 19s 131ms/step - loss: 0.1463 - accuracy: 0.9525 - val_loss: 0.1472 - val_accuracy: 0.9471\n\nEpoch 00027: val_accuracy did not improve from 0.95051\nEpoch 00027: early stopping\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model('save_models/effnet.h5')\n\nfor layer in model.layers[-20:]:#let's unfreeze some layers, the 20 last ones\n    if not isinstance(layer, BatchNormalization):\n        layer.trainable = True\n\nfilepath = \"save_models/effnet_FT.h5\"\n\ncallbacks = [ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1),\n           EarlyStopping(monitor='val_accuracy', patience=10, verbose=1),\n           ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, verbose=1)]\n\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(lr=1e-3), #we reduce a bit the LR\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_valid, y_valid), callbacks=callbacks)","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n147/147 [==============================] - 88s 539ms/step - loss: 0.4435 - accuracy: 0.8705 - val_loss: 0.6000 - val_accuracy: 0.7765\n\nEpoch 00001: val_accuracy improved from -inf to 0.77645, saving model to save_models/effnet_FT.h5\nEpoch 2/50\n147/147 [==============================] - 78s 530ms/step - loss: 0.1449 - accuracy: 0.9478 - val_loss: 0.4439 - val_accuracy: 0.8191\n\nEpoch 00002: val_accuracy improved from 0.77645 to 0.81911, saving model to save_models/effnet_FT.h5\nEpoch 3/50\n147/147 [==============================] - 77s 527ms/step - loss: 0.1061 - accuracy: 0.9608 - val_loss: 0.3659 - val_accuracy: 0.8618\n\nEpoch 00003: val_accuracy improved from 0.81911 to 0.86177, saving model to save_models/effnet_FT.h5\nEpoch 4/50\n147/147 [==============================] - 77s 521ms/step - loss: 0.0731 - accuracy: 0.9676 - val_loss: 0.2247 - val_accuracy: 0.9181\n\nEpoch 00004: val_accuracy improved from 0.86177 to 0.91809, saving model to save_models/effnet_FT.h5\nEpoch 5/50\n147/147 [==============================] - 77s 524ms/step - loss: 0.0696 - accuracy: 0.9767 - val_loss: 0.1017 - val_accuracy: 0.9625\n\nEpoch 00005: val_accuracy improved from 0.91809 to 0.96246, saving model to save_models/effnet_FT.h5\nEpoch 6/50\n147/147 [==============================] - 79s 538ms/step - loss: 0.0595 - accuracy: 0.9764 - val_loss: 0.1193 - val_accuracy: 0.9590\n\nEpoch 00006: val_accuracy did not improve from 0.96246\nEpoch 7/50\n147/147 [==============================] - 77s 526ms/step - loss: 0.0643 - accuracy: 0.9790 - val_loss: 0.1373 - val_accuracy: 0.9608\n\nEpoch 00007: val_accuracy did not improve from 0.96246\nEpoch 8/50\n147/147 [==============================] - 77s 523ms/step - loss: 0.0414 - accuracy: 0.9856 - val_loss: 0.0854 - val_accuracy: 0.9693\n\nEpoch 00008: val_accuracy improved from 0.96246 to 0.96928, saving model to save_models/effnet_FT.h5\nEpoch 9/50\n147/147 [==============================] - 78s 529ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0940 - val_accuracy: 0.9573\n\nEpoch 00009: val_accuracy did not improve from 0.96928\nEpoch 10/50\n147/147 [==============================] - 79s 534ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.1292 - val_accuracy: 0.9573\n\nEpoch 00010: val_accuracy did not improve from 0.96928\nEpoch 11/50\n147/147 [==============================] - 78s 529ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.1038 - val_accuracy: 0.9659\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 00011: val_accuracy did not improve from 0.96928\nEpoch 12/50\n147/147 [==============================] - 78s 532ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0962 - val_accuracy: 0.9710\n\nEpoch 00012: val_accuracy improved from 0.96928 to 0.97099, saving model to save_models/effnet_FT.h5\nEpoch 13/50\n147/147 [==============================] - 78s 533ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0931 - val_accuracy: 0.9744\n\nEpoch 00013: val_accuracy improved from 0.97099 to 0.97440, saving model to save_models/effnet_FT.h5\nEpoch 14/50\n147/147 [==============================] - 79s 536ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1138 - val_accuracy: 0.9744\n\nEpoch 00014: val_accuracy did not improve from 0.97440\nEpoch 15/50\n147/147 [==============================] - 78s 529ms/step - loss: 0.0063 - accuracy: 0.9969 - val_loss: 0.1392 - val_accuracy: 0.9659\n\nEpoch 00015: val_accuracy did not improve from 0.97440\nEpoch 16/50\n147/147 [==============================] - 77s 524ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1406 - val_accuracy: 0.9573\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 00016: val_accuracy did not improve from 0.97440\nEpoch 17/50\n147/147 [==============================] - 77s 524ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1254 - val_accuracy: 0.9642\n\nEpoch 00017: val_accuracy did not improve from 0.97440\nEpoch 18/50\n147/147 [==============================] - 76s 520ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 0.1150 - val_accuracy: 0.9710\n\nEpoch 00018: val_accuracy did not improve from 0.97440\nEpoch 19/50\n147/147 [==============================] - 77s 522ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1158 - val_accuracy: 0.9710\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 00019: val_accuracy did not improve from 0.97440\nEpoch 20/50\n147/147 [==============================] - 77s 521ms/step - loss: 4.6274e-04 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9710\n\nEpoch 00020: val_accuracy did not improve from 0.97440\nEpoch 21/50\n147/147 [==============================] - 77s 524ms/step - loss: 4.2407e-04 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9693\n\nEpoch 00021: val_accuracy did not improve from 0.97440\nEpoch 22/50\n147/147 [==============================] - 77s 526ms/step - loss: 4.7387e-04 - accuracy: 0.9999 - val_loss: 0.1126 - val_accuracy: 0.9727\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 00022: val_accuracy did not improve from 0.97440\nEpoch 23/50\n147/147 [==============================] - 78s 530ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1128 - val_accuracy: 0.9693\n\nEpoch 00023: val_accuracy did not improve from 0.97440\nEpoch 00023: early stopping\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\nmodel = load_model('save_models/effnet_FT.h5')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)\ny_pred = np.array([0 if val<0.5 else 1 for val in pred])\ny_pred = np.expand_dims(y_pred, axis=-1)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CM = confusion_matrix(y_test, y_pred)\nfig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\nplt.show()","execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 360x360 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAATkAAAE9CAYAAABwcBXnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAARnUlEQVR4nO3de7Sc87nA8e+TkIMIoeKWKIlbGjluQShaddBIU7e6NG2XSxSHOrTqdpZbdempltOjtKekpWqpW1sqx7Uup0gI4hpEUJdKaCNU5CSIJL/zx56kWy7bYN49s59+P2vtteedefe8z1jxXe87M+9MlFKQpKy6NXsASaqSkZOUmpGTlJqRk5SakZOUmpGTlNoyzR6gvZVWWbX0WWudZo+hFtV7+WWbPYJa1Esvvcj06dNjSbe1VOT6rLUOP7ji5maPoRY1YvDazR5BLWr7oVst9TYPVyWlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuQkpWbkJKVm5CSlZuSa5L+/cxyH7rwpx+2782K3jbnsQvbboi9v/e0NAO656VqOP2DXhT/7b9mPFyY/0dkjqwU8M3kyQ4dsvvBn9VVX4oIfn9fssVraMlXeeUQMA34MdAd+UUo5u8rtdSU7fXF/hh1wCD857dj3XT/9L1N5fPzdrLZm34XX7Th8H3Ycvg8ALz07iR9+axT9Nx7cqfOqNWy08cbc/9CjAMybN4/11+3LHnvt3dyhWlxle3IR0R34KbA7MAgYGRGDqtpeVzNoyLasuHLvxa6/9Nzv8LVjTyEilvh34275PdsP27Pi6dQV/O+dd9B/wPqsu+66zR6lpVV5uLoN8Fwp5flSyhzgKsD/Ozvw4B//wKqrr8V6G2+y1HXu/cP/sMOwvTpvKLWs31x9FfsfMLLZY7S8KiPXF3i53fKU2nVagnfffptrLz6fA448fqnrPDvxYXostzyf3GBgJ06mVjRnzhxuvGEM++y7X7NHaXlVRm5Jx1tlsZUiDo+ICREx4a03X69wnNb2lykvMm3qnznhgF05avhQXp/2Kid+5fP8bfq0heuMu/V6dvBQVcCtt9zM5ltsyRprrNHsUVpelS88TAHWabfcD3hl0ZVKKaOB0QDrD9pssQj+o1h3w09x8Z2PL1w+avhQzv71zay0yqoAzJ8/n/tuu4HvXnxts0ZUC7nm6is9VK1TlXtyDwIbRkT/iOgBfBkYU+H2upTzTj6KUw7ag1de+hNHfH4Id1x3ZYfrT3p4PJ9YYy3W6OeTzP/oZs+ezZ2338aee+/T7FG6hCilup2niBgOnEfbW0guKaV8r6P11x+0WfnBFTdXNo+6thGD1272CGpR2w/diocemrDEtyRU+j65UspNwE1VbkOSOuIZD5JSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUjNyklIzcpJSM3KSUltmaTdExEygLFis/S61y6WUslLFs0nSx7bUyJVSenXmIJJUhboOVyNih4g4pHZ5tYjoX+1YktQYHxi5iDgDOAn499pVPYDLqxxKkhqlnj25vYE9gFkApZRXAA9lJXUJ9URuTimlUHsRIiJ6VjuSJDVOPZG7JiIuAnpHxGHA7cDPqx1Lkhpjqa+uLlBKOTcidgXeAjYCTi+l3Fb5ZJLUAB8YuZqJwPK0HbJOrG4cSWqsel5d/TrwALAPsC8wPiJGVT2YJDVCPXtyJwBblFJeB4iITwD3ApdUOZgkNUI9LzxMAWa2W54JvFzNOJLUWB2du3pc7eJU4P6IuJ625+T2pO3wVZJaXkeHqwve8Pun2s8C11c3jiQ1Vkcn6J/ZmYNIUhU+8IWHiOgDnAhsAiy34PpSys4VziVJDVHPCw+/Bp4G+gNnAi8CD1Y4kyQ1TD2R+0Qp5WLgvVLKXaWUUcC2Fc8lSQ1Rz/vk3qv9fjUivgC8AvSrbiRJapx6IndWRKwMfBu4AFgJ+FalU0lSg9Rzgv4NtYszgM9VO44kNVZHbwa+gL9/kc1iSinHVDKRJDVQR3tyEzptipreyy/LiMFrd/Zm1UWssvXRzR5BLerdyX9e6m0dvRn4V5VMI0mdyC+XlpSakZOUmpGTlFo9nwy8UUTcERFP1JY3jYhTqx9Nkj6+evbkfk7bF0u/B1BKeRz4cpVDSVKj1BO5FUopi35I5twqhpGkRqsnctMjYn3+/uXS+wKvVjqVJDVIPeeufgMYDQyMiKnAC8DXKp1KkhqknnNXnwd2iYieQLdSyswP+htJahX1fDLw6YssA1BK+W5FM0lSw9RzuDqr3eXlgBHApGrGkaTGqudw9T/bL0fEucCYyiaSpAb6KGc8rAAMaPQgklSFep6Tm8jfP1euO9AH8Pk4SV1CPc/JjWh3eS7w11KKbwaW1CV0GLmI6AbcWEoZ3EnzSFJDdficXCllPvBYRHyyk+aRpIaq53B1LeDJiHiAdm8nKaXsUdlUktQg9UTuzMqnkKSK1BO54aWUk9pfERE/AO6qZiRJapx63ie36xKu273Rg0hSFTr63tUjgaOAARHxeLubegHjqh5Mkhqho8PVK4Cbge8DJ7e7fmYp5Y1Kp5KkBunoe1dnADOAkZ03jiQ1lt/WJSk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJyk1IycpNSMnKTUjJym1ZZo9gBb35ptvcuQRX+epJ58gIrhw9CVsu912zR5Lnaxbt2Dcr0/klWkz+NKxF/If39yL4Z8ZzJz35vHClOkcfsblzPi/twEYvOHa/OTUkfTquRzz5xd2+NoPeXfO3CY/gtZQWeQi4hJgBDCtlDK4qu1kdPy3jmW33YZx5dW/Zc6cOcyePbvZI6kJjv7K55j8wl/p1XM5AO4Y/zSnXTCGefPmc9Yxe3LCqN049fzr6d69G5ecdRCHnnYZE5+Zyqor9+S9ufOaPH3rqPJw9VJgWIX3n9Jbb73F2LF3c/CoQwHo0aMHvXv3bu5Q6nR9V+/NsB024ZfX3bvwujvGP828efMBeGDiC/RdozcAu2w3kCeencrEZ6YC8MaMWcyfXzp95lZVWeRKKXcDb1R1/1m98PzzrLZaHw4/9BC23WoLjjz868yaNavZY6mTnXPClzjlx79faqwO3HM7bh33FAAbfnJ1SoExP/0G915xEscdtEtnjtryfOGhxcydO5dHH3mYw444kvETHmGFnj0594dnN3ssdaLddxzMtDdm8sikl5d4+4mHfp558+Zz1U0PArBM9+58eosBHHLKpfzLqB+xx86bsdM2G3XmyC2t6ZGLiMMjYkJETHht+mvNHqfp+vbrR99+/dhm6FAA9v7Svjz6yMNNnkqdabvNBzDis//M0zeeyWVnH8JOW2/EJWcdCMBXvziU4Z8ZzMGnXLpw/anT3uSeh57j9Tdn8fY773HL2CfZYuA6TZq+9TQ9cqWU0aWUrUopW/VZrU+zx2m6Nddck3791uGZyZMB+OOddzDwU4OaPJU60+kXjGGDYacx8AtncODJv+SPDz7DqFMvY9dPf4pvH7wL+37zIt5+572F699271MM3rAvyy+3LN27d2PHIRsw6fm/NPERtBbfQtKCfnTeBRxy4FeZM2cO6w0YwOhf/LLZI6kF/NdJ+/NPPZbhhp8dDcADE1/kmO9dxZsz3+b8y+9k7OUnUkrh1rFPcsvYJ5s8beuIUqp5FSYirgR2AlYD/gqcUUq5uKO/GTJkqzLu/gmVzKOub5Wtj272CGpR706+hvmzp8WSbqtsT66UMrKq+5akejX9OTlJqpKRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUmpGTlJqRk5SakZOUWpRSmj3DQhHxGvBSs+doIasB05s9hFqS/zbeb91SSp8l3dBSkdP7RcSEUspWzZ5Drcd/G/XzcFVSakZOUmpGrrWNbvYAaln+26iTz8lJSs09OUmpGbkWFBHDImJyRDwXESc3ex61joi4JCKmRcQTzZ6lqzByLSYiugM/BXYHBgEjI2JQc6dSC7kUGNbsIboSI9d6tgGeK6U8X0qZA1wF7NnkmdQiSil3A280e46uxMi1nr7Ay+2Wp9Suk/QRGLnWE0u4zpfApY/IyLWeKcA67Zb7Aa80aRapyzNyredBYMOI6B8RPYAvA2OaPJPUZRm5FlNKmQscDdwKTAKuKaU82dyp1Coi4krgPmDjiJgSEYc2e6ZW5xkPklJzT05SakZOUmpGTlJqRk5SakZOUmpGTpWLiJ0i4oba5T06+mSViOgdEUd9hG18JyKOr/f6Rda5NCL2/RDbWs9PAek6jJw+stonpnwopZQxpZSzO1ilN/ChIyctjZHTYmp7Kk9HxK8i4vGI+G1ErFC77cWIOD0ixgL7RcRuEXFfRDwcEb+JiBVr6w2r3cdYYJ92931wRPykdnmNiLguIh6r/XwaOBtYPyIejYhzauudEBEP1mY5s919nVL73L3bgY3reFyH1e7nsYj43YLHVLNLRNwTEc9ExIja+t0j4px22z7i4/63VeczclqajYHRpZRNgbd4/97VO6WUHYDbgVOBXUopWwITgOMiYjng58AXgR2BNZeyjfOBu0opmwFbAk8CJwN/KqVsXko5ISJ2Azak7SOoNgeGRMRnImIIbae8bUFbRLeu4zFdW0rZura9SUD7swXWAz4LfAG4sPYYDgVmlFK2rt3/YRHRv47tqIUs0+wB1LJeLqWMq12+HDgGOLe2fHXt97a0fbDnuIgA6EHbKUcDgRdKKc8CRMTlwOFL2MbOwIEApZR5wIyIWGWRdXar/TxSW16Rtuj1Aq4rpcyubaOe83sHR8RZtB0Sr0jbqXMLXFNKmQ88GxHP1x7DbsCm7Z6vW7m27Wfq2JZahJHT0ix6vl/75Vm13wHcVkoZ2X7FiNh8CX//UQXw/VLKRYts45sfYRuXAnuVUh6LiIOBndrdtqTHG8C/lVLax5CIWO9DbldN5OGqluaTEbFd7fJIYOwS1hkPbB8RGwBExAoRsRHwNNA/ItZv9/dLcgdwZO1vu0fESsBM2vbSFrgVGNXuub6+EbE6cDewd0QsHxG9aDs0/iC9gFcjYlngq4vctl9EdKvNPACYXNv2kbX1iYiNIqJnHdtRCzFyWppJwEER8TiwKvCzRVcopbwGHAxcWVtvPDCwlPIObYenN9ZeeHhpKds4FvhcREwEHgI2KaW8Ttvh7xMRcU4p5Q/AFcB9tfV+C/QqpTxM22Hzo8DvgHvqeEynAfcDt9EW4vYmA3cBNwP/WnsMvwCeAh6uvWXkIjz66XL8FBItpnY4dkMpZXCzZ5E+LvfkJKXmnpyk1NyTk5SakZOUmpGTlJqRk5SakZOUmpGTlNr/A3Jtzq6gRYr1AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TP=426\nFP=7\nFN=6\nTN=147","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision, recall, F1_score = get_scores(y_test, y_pred)\n\nprint (f\"recall = {recall:05f}\")\nprint (f\"precision = {precision:05f}\")\nprint (f\"F1_score = {F1_score:05f}\")","execution_count":16,"outputs":[{"output_type":"stream","text":"recall = 0.986111\nprecision = 0.983834\nF1_score = 0.984971\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_accuracy=(TP + TN)/(TP + TN + FP + FN)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_accuracy)","execution_count":36,"outputs":[{"output_type":"stream","text":"0.9778156996587031\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}